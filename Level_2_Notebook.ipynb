{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "cf32eea5-5306-56b9-af53-cd0ff245e001",
        "openai_ephemeral_user_id": "6e0de5be-ff09-5930-90fb-69f73f3175a3",
        "openai_subdivision1_iso_code": "US-IL"
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "noteable": {
      "last_transaction_id": "e40d2e64-9753-4c95-9e30-8d9e7d61ea09"
    },
    "kernelspec": {
      "display_name": "Python 3.9",
      "language": "python",
      "name": "python3"
    },
    "selected_hardware_size": "small"
  },
  "cells": [
    {
      "id": "af05fc50-a8e2-4288-b38e-ee0206c5ee66",
      "cell_type": "markdown",
      "source": "# Level 2 Software Quality Notebook\n",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "64457137-f441-478d-9bc0-4eafdce278e5",
      "cell_type": "markdown",
      "source": "## General Introduction\nThis series of notebooks is designed to develop a framework for measuring software quality metrics and their corresponding controls in Jira. By leveraging data from various sources such as Jira, GitHub, and customer feedback platforms, we aim to build multi-level data products (Level 0-4) that provide insights into software development processes and quality assurance.\n\n## Level 2 Notebook Introduction\nThe Level 2 Notebook builds upon the cleaned data from Level 1 by incorporating customer feedback from various signal sources like Amplitude, Qualtrics, and Call Miner. By joining this feedback data with existing datasets on GitHub commits, Jira issues, defects, and team structures, we aim to create a multi-dimensional view of software quality. Tasks include normalizing feedback data, time-series analysis, data visualization, and preparation for next levels.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "bf654497-989b-4544-9b27-209e5a6ff3d4",
      "cell_type": "markdown",
      "source": "## Data Alignment with Primary Key\nOnce the customer feedback data is collected from Amplitude, Qualtrics, and Call Miner, the next step is to align this data with the previously identified primary key. This alignment ensures consistency across datasets and enables seamless integration with existing data from Level 1.\n\n### Steps for Data Alignment\n1. **Identify Common Elements**: Determine the common elements in the collected data that correspond to the primary key (e.g., Customer ID, Feature ID, etc.).\n2. **Map to Primary Key**: Map the identified common elements to the primary key used in previous levels. This may involve data transformations or conversions.\n3. **Handle Missing or Inconsistent Data**: Implement strategies to handle missing or inconsistent data in the alignment process. This may include imputation, exclusion, or other data cleaning techniques.\n4. **Verify Alignment**: Perform checks to verify that the alignment is correct and that the data is consistent across sources.\n\nBy aligning the collected data with the primary key, we ensure that the customer feedback data can be accurately integrated with existing datasets, providing a comprehensive view of software quality metrics and user feedback.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "e9fef0d2-5497-467e-b55e-de375360b411",
      "cell_type": "markdown",
      "source": "## Data Preprocessing and Normalization\nAfter aligning the collected data with the primary key, the next step is to preprocess and normalize the data. This ensures that the data is in a suitable format for analysis and integration with existing datasets.\n\n### Steps for Data Preprocessing and Normalization\n1. **Handle Missing Values**: Implement strategies to handle missing values in the collected data. This may include imputation, exclusion, or other techniques.\n2. **Categorize Feedback**: Categorize customer feedback into relevant groups or themes for analysis. This may involve text analysis, sentiment analysis, or other methods.\n3. **Standardize Date Formats**: Ensure that date formats are consistent across datasets, allowing for accurate time-series analysis.\n4. **Normalize Data**: Apply normalization techniques to standardize the scale of numerical variables, if necessary.\n\nThese preprocessing and normalization steps prepare the data for integration with Level 1 data and subsequent analysis, ensuring that the data is clean, consistent, and ready for exploration.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "e34d6dc0-06df-4d49-9734-23288850e281",
      "cell_type": "markdown",
      "source": "## Data Integration with Level 1 Data\nWith the collected customer feedback data aligned, preprocessed, and normalized, the next step is to integrate this data with the cleaned data from Level 1. This integration creates a comprehensive dataset that includes information from GitHub commits, Jira issues, defects, team structures, and customer feedback.\n\n### Steps for Data Integration\n1. **Join Datasets**: Use the primary key to join the collected data with the Level 1 data. This may involve inner joins, outer joins, or other join techniques.\n2. **Resolve Conflicts**: Identify and resolve any conflicts or inconsistencies that may arise during the join process.\n3. **Verify Integration**: Perform checks to verify that the integration is successful and that the data is consistent across sources.\n4. **Prepare for Analysis**: Structure the integrated data for further analysis, including potential machine learning models, predictions, and advanced analytics.\n\nThe successful integration of customer feedback data with existing datasets provides a rich and multi-dimensional view of software quality metrics, enabling deeper insights and more informed decision-making.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "da84e3e7-e5b3-41d8-a19d-72c5845cbf07",
      "cell_type": "markdown",
      "source": "## Vendor Data Sources Documentation\nIn this section, we provide an overview of the available data and recommendations for Amplitude, Call Miner, and Qualtrics. Understanding the API endpoints, schemas, and data formats will simplify the process of collecting and applying the data.\n",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "2934fdef-6a33-4d7c-b26f-6594b0a2c464",
      "cell_type": "markdown",
      "source": "### Amplitude\n- **API Documentation**: [Amplitude API Documentation](https://developers.amplitude.com/docs)\n- **Data Schema**: The data schema typically includes user behavior data, such as events, user properties, and device information.\n- **Data Formats**: JSON is commonly used for data exchange with Amplitude's API.\n\n### Call Miner\n- **API Documentation**: [Call Miner API Documentation](https://callminer.com/api-documentation/)\n- **Data Schema**: Call Miner's schema may include call transcripts, sentiment analysis, and other speech analytics data.\n- **Data Formats**: The data format may vary, and specific details can be found in the API documentation.\n\n### Qualtrics\n- **API Documentation**: [Qualtrics API Documentation](https://api.qualtrics.com/)\n- **Data Schema**: Qualtrics provides survey data, including responses, questions, and metadata.\n- **Data Formats**: JSON and CSV are common data formats used with Qualtrics' API.\n\nThese details offer a comprehensive view of the available data from each vendor, aiding in the collection and integration process. It's advisable to consult the official API documentation and any available developer guides for detailed information tailored to specific needs.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    }
  ]
}